{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMImF7zpz7LuybjqsQ1wSab",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GaurangRawat/Langchain/blob/main/API_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install FastAPI langchain langserve langchain_community os uvicorn python-dotenv"
      ],
      "metadata": {
        "id": "MSDP3cAcLS5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from fastapi import FastAPI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langserve import add_routes\n",
        "import uvicorn\n",
        "import os\n",
        "from langchain_community.llms import Ollama\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "app=FastAPI(\n",
        "    title=\"Langchain Server\",\n",
        "    version=\"1.0\",\n",
        "    decsription=\"A simple API Server\"\n",
        "\n",
        ")\n",
        "\n",
        "add_routes(\n",
        "    app,\n",
        "    ChatOpenAI(),\n",
        "    path=\"/openai\"\n",
        ")\n",
        "model=ChatOpenAI()\n",
        "##ollama llama2\n",
        "llm=Ollama(model=\"llama2\")\n",
        "\n",
        "prompt1=ChatPromptTemplate.from_template(\"Write me an essay about {topic} with 100 words\")\n",
        "prompt2=ChatPromptTemplate.from_template(\"Write me an poem about {topic} for a 5 years child with 100 words\")\n",
        "\n",
        "add_routes(\n",
        "    app,\n",
        "    prompt1|model,\n",
        "    path=\"/essay\"\n",
        "\n",
        "\n",
        ")\n",
        "\n",
        "add_routes(\n",
        "    app,\n",
        "    prompt2|llm,\n",
        "    path=\"/poem\"\n",
        "\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    uvicorn.run(app,host=\"localhost\",port=8000)\n"
      ],
      "metadata": {
        "id": "daXzpL-7LRNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile client.py\n",
        "from fastapi import FastAPI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langserve import add_routes\n",
        "import uvicorn\n",
        "import os\n",
        "from langchain_community.llms import Ollama\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "app=FastAPI(\n",
        "    title=\"Langchain Server\",\n",
        "    version=\"1.0\",\n",
        "    decsription=\"A simple API Server\"\n",
        "\n",
        ")\n",
        "\n",
        "add_routes(\n",
        "    app,\n",
        "    ChatOpenAI(),\n",
        "    path=\"/openai\"\n",
        ")\n",
        "model=ChatOpenAI()\n",
        "##ollama llama2\n",
        "llm=Ollama(model=\"llama2\")\n",
        "\n",
        "prompt1=ChatPromptTemplate.from_template(\"Write me an essay about {topic} with 100 words\")\n",
        "prompt2=ChatPromptTemplate.from_template(\"Write me an poem about {topic} for a 5 years child with 100 words\")\n",
        "\n",
        "add_routes(\n",
        "    app,\n",
        "    prompt1|model,\n",
        "    path=\"/essay\"\n",
        "\n",
        "\n",
        ")\n",
        "\n",
        "add_routes(\n",
        "    app,\n",
        "    prompt2|llm,\n",
        "    path=\"/poem\"\n",
        "\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    uvicorn.run(app,host=\"localhost\",port=8000)\n"
      ],
      "metadata": {
        "id": "Vlih-SqARvXP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}